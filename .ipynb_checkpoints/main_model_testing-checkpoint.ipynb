{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acertar o backend e libertar mem처ria da grafica\n"
     ]
    }
   ],
   "source": [
    "#para melhor gest찾o mem처ria GPU por parte do tensorflow\n",
    "\n",
    "import tensorflow as tf    \n",
    "\n",
    " \n",
    "\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    print(\"A acertar o backend e libertar mem처ria da grafica\")\n",
    "\n",
    "    if K.backend() != backend:\n",
    "\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "\n",
    "        importlib.reload(K)\n",
    "\n",
    "        assert K.backend() == backend\n",
    "\n",
    "    if backend == \"tensorflow\":\n",
    "\n",
    "        config = tf.ConfigProto()\n",
    "\n",
    "        config.gpu_options.allow_growth = True\n",
    "\n",
    "        session = tf.Session(config=config)\n",
    "\n",
    "       \n",
    "\n",
    "def limit_mem():\n",
    "\n",
    "    K.get_session().close()\n",
    "\n",
    "    cfg = K.tf.ConfigProto()\n",
    "\n",
    "    cfg.gpu_options.allow_growth = True\n",
    "\n",
    "    K.set_session(K.tf.Session(config=cfg))\n",
    "\n",
    " \n",
    "\n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38652, 3)\n",
      "['Doing other things' 'Swiping Down' 'Swiping Left'\n",
      " 'Zooming In With Full Hand']\n",
      "Part_02/3170\n",
      "[0]\n",
      "(38652, 1)\n",
      "(38652, 1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "path = \"gesture_dataset\"\n",
    "\n",
    "from load_custom_dataset import My_Custom_Generator,prepare_filenames_without_trainning,prepare_filenames_with_trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filenames, X_val_filenames, X_test_filenames, y_train, y_val, y_test = prepare_filenames_without_trainning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "my_validation_batch_generator = My_Custom_Generator(X_val_filenames, y_val, batch_size)\n",
    "my_test_batch_generator = My_Custom_Generator(X_test_filenames,y_test, batch_size)\n",
    "my_training_batch_generator = My_Custom_Generator(X_train_filenames, y_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Add, LSTM, ConvLSTM2D,Conv3D,Reshape\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import AveragePooling2D, MaxPooling3D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, GlobalAveragePooling3D, ZeroPadding3D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from keras.utils import plot_model\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.optimizers import Adam,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef build_model():\\n    model = Sequential()\\n   \\n    model.add(Conv3D(32, (3, 3, 3), activation=\\'relu\\',\\n                            padding=\\'same\\', name=\\'conv1\\',\\n                            strides=(1,2,2),\\n                            input_shape=(36,75,100,3)) )\\n    \\n    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\\n                           padding=\\'valid\\', name=\\'pool1\\'))\\n    # 2nd layer group\\n    model.add(Conv3D(128, (3, 3, 3), activation=\\'relu\\',\\n                            padding=\\'same\\', name=\\'conv2\\'))\\n    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\\n                           padding=\\'valid\\', name=\\'pool2\\'))\\n    # 3rd layer group\\n    model.add(Conv3D(256, (3, 3, 3), activation=\\'relu\\',\\n                            padding=\\'same\\', name=\\'conv3a\\'))\\n    model.add(Conv3D(256, (3, 3, 3), activation=\\'relu\\',\\n                            padding=\\'same\\', name=\\'conv3b\\'))\\n    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\\n                           padding=\\'valid\\', name=\\'pool3\\'))\\n    # 4th layer group\\n    model.add(Conv3D(512, (3, 3, 3), activation=\\'relu\\',\\n                            padding=\\'same\\', name=\\'conv4a\\'))\\n    model.add(Conv3D(512, (3, 3, 3), activation=\\'relu\\',\\n                            padding=\\'same\\', name=\\'conv4b\\'))\\n    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\\n                           padding=\\'valid\\', name=\\'pool4\\'))\\n    \\n    model.add(ZeroPadding3D(padding=((0, 0), (0, 1), (0, 1)), name=\\'zeropad5\\'))\\n    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\\n                           padding=\\'valid\\', name=\\'pool5\\'))\\n    # FC layers group\\n    #model.add(Dense(2048, activation=\\'relu\\', name=\\'fc6\\'))\\n    #model.add(GlobalAveragePooling3D())\\n    model.add(Reshape((-1,512)))\\n    model.add(CuDNNLSTM(1024))\\n    #model.add(Dropout(.5))\\n    #model.add(Dense(2048, activation=\\'relu\\', name=\\'fc7\\'))\\n    #model.add(Dropout(.5))\\n    model.add(Dense(4, activation=\\'softmax\\', name=\\'fc8\\'))\\n    \\n    adam = Adam(0.001, decay = 0.001/50)\\n    sgd = SGD(nesterov=True,momentum=0.9,decay= 0.001/50)\\n    model.compile(optimizer = sgd, loss = \"sparse_categorical_crossentropy\" , metrics = [keras.metrics.sparse_categorical_accuracy])\\n    \\n    return model\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "   \n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv1',\n",
    "                            strides=(1,2,2),\n",
    "                            input_shape=(36,75,100,3)) )\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                           padding='valid', name='pool1'))\n",
    "    # 2nd layer group\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv2'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool2'))\n",
    "    # 3rd layer group\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv3a'))\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv3b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool3'))\n",
    "    # 4th layer group\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv4a'))\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv4b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool4'))\n",
    "    \n",
    "    model.add(ZeroPadding3D(padding=((0, 0), (0, 1), (0, 1)), name='zeropad5'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool5'))\n",
    "    # FC layers group\n",
    "    #model.add(Dense(2048, activation='relu', name='fc6'))\n",
    "    #model.add(GlobalAveragePooling3D())\n",
    "    model.add(Reshape((-1,512)))\n",
    "    model.add(CuDNNLSTM(1024))\n",
    "    #model.add(Dropout(.5))\n",
    "    #model.add(Dense(2048, activation='relu', name='fc7'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(Dense(4, activation='softmax', name='fc8'))\n",
    "    \n",
    "    adam = Adam(0.001, decay = 0.001/50)\n",
    "    sgd = SGD(nesterov=True,momentum=0.9,decay= 0.001/50)\n",
    "    model.compile(optimizer = sgd, loss = \"sparse_categorical_crossentropy\" , metrics = [keras.metrics.sparse_categorical_accuracy])\n",
    "    \n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "   \n",
    "    model.add(Conv3D(16, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv1',\n",
    "                            strides=(1,2,2),\n",
    "                            input_shape=(36,75,100,3)) )\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                           padding='valid', name='pool1'))\n",
    "    # 2nd layer group\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv2'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool2'))\n",
    "    # 3rd layer group\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv3a'))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv3b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool3'))\n",
    "    # 4th layer group\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv4a'))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu',\n",
    "                            padding='same', name='conv4b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool4'))\n",
    "    \n",
    "    model.add(ZeroPadding3D(padding=((0, 0), (0, 1), (0, 1)), name='zeropad5'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool5'))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Reshape((-1,256)))\n",
    "    #model.add(CuDNNLSTM(256))\n",
    "    model.add(Dense(4, activation='softmax', name='fc8'))\n",
    "    \n",
    "    adam = Adam(0.001, decay = 0.001/50)\n",
    "    sgd = SGD(nesterov=True,momentum=0.9)\n",
    "    model.compile(optimizer = sgd, loss = \"sparse_categorical_crossentropy\" , metrics = [keras.metrics.sparse_categorical_accuracy])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 36, 38, 50, 16)    1312      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 36, 19, 25, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 36, 19, 25, 32)    13856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 18, 9, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 18, 9, 12, 64)     55360     \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 18, 9, 12, 64)     110656    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 9, 4, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 9, 4, 6, 128)      221312    \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 9, 4, 6, 128)      442496    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 4, 2, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 4, 3, 4, 128)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 2, 1, 2, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 847,044\n",
      "Trainable params: 847,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model,custom_generator,my_validation_batch_generator,batch_size):\n",
    "    \n",
    "    #i can use this EarlyStopping to stop my CNN to a possible overfitting \n",
    "    callbacks = [\n",
    "        #MyCustomCallback(custom_generator),\n",
    "        \n",
    "        #LearningRateScheduler(lr_scheduler, verbose=1),\n",
    "\n",
    "        ModelCheckpoint(filepath='best_model_{epoch}_sgd_nesterov_800k_custom_dataset.h5',\n",
    "                        monitor='val_loss',\n",
    "                        verbose=2,\n",
    "                        save_weights_only=False,\n",
    "                        save_best_only=True,\n",
    "                        mode='min',\n",
    "                        period = 1\n",
    "                        ),\n",
    "        CSVLogger('training_sgd_nesterov_800k_custom_dataset.log',append=True)#,\n",
    "        #PlotLossesKeras()\n",
    "        \n",
    "    ]\n",
    "\n",
    "    history = model.fit(x = custom_generator,\n",
    "                   #steps_per_epoch = int(12198 // batch_size),\n",
    "                   epochs = 50,\n",
    "                   verbose = 1,\n",
    "                   validation_data = my_validation_batch_generator,\n",
    "                   #validation_steps = int(4066 // batch_size),             \n",
    "                   callbacks = callbacks,\n",
    "                   initial_epoch=0    #target is 50 epochs -> done: [...]\n",
    "                   )\n",
    "    \n",
    "    return history,model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 32/968 [..............................] - ETA: 35:14 - loss: 1.3787 - sparse_categorical_accuracy: 0.3027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c0bd6843e442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Agora treinamos a rede com o generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_training_batch_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_validation_batch_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f95054fcfb11>\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(model, custom_generator, my_validation_batch_generator, batch_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m                    \u001b[0;31m#validation_steps = int(4066 // batch_size),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                    \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                    \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m    \u001b[0;31m#target is 50 epochs -> done: [...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                    )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Agora treinamos a rede com o generator\n",
    "history,model = model_fit(model,my_training_batch_generator,my_validation_batch_generator,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "def print_history_accuracy(history,path):\n",
    "    print(history.history.keys())\n",
    "    if 'sparse_categorical_accuracy' in history.history.keys():\n",
    "        plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "        plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "    else:\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "  \n",
    "    plt.savefig(path)\n",
    "  \n",
    "    plt.show()\n",
    "\n",
    "def print_history_loss(history,path):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    plt.savefig(path)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def print_model(model,name):\n",
    "    from keras.utils import plot_model \n",
    "    plot_model(model, to_file=name, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    \n",
    "print_history_accuracy(history,'./accuracy_learning_curve')\n",
    "print_history_loss(history,'./loss_learning_curve')\n",
    "print_model(model,'training_sgd_nesterov_800k_custom_dataset.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "test_model = load_model('custom_dataset_800K_model/best_model_13_sgd_nesterov_800k_custom_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 70s 576ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05076095163182371, 0.9870867768595041]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.evaluate(my_test_batch_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
