{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread,Lock\n",
    "import cv2\n",
    "import time\n",
    "from time import monotonic as timer\n",
    "import os\n",
    "import numpy as np\n",
    "import queue\n",
    "from ExecuteGesture import scale,swipe,minimize\n",
    "from pynput.keyboard import Key\n",
    "import threading\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "from imutils.video import WebcamVideoStream\n",
    "from imutils.video import FPS\n",
    "import imutils\n",
    "from IPython.display import display\n",
    "from cv2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class CountsPerSec:\n",
    "    \"\"\"\n",
    "    Class that tracks the number of occurrences (\"counts\") of an\n",
    "    arbitrary event and returns the frequency in occurrences\n",
    "    (counts) per second. The caller must increment the count.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "        self._num_occurrences = 0\n",
    "\n",
    "    def start(self):\n",
    "        self._start_time = datetime.now()\n",
    "        return self\n",
    "\n",
    "    def increment(self):\n",
    "        self._num_occurrences += 1\n",
    "\n",
    "    def countsPerSec(self):\n",
    "        \n",
    "        elapsed_time = (datetime.now() - self._start_time).total_seconds()\n",
    "        return self._num_occurrences / elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/guilhermeviveiros/Desktop/models/research/object_detection\"\n",
    "MODEL_NAME = 'hand_graph'\n",
    "PATH_TO_CKPT = path + '/' + MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = os.path.join(path+'/training', 'labelmap.pbtxt')\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.compat.v1.get_default_graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "label_map_util.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vou escolher random entre as frames que tenho num segundo até ter 12 frames\n",
    "#Exemplo -> Se obtiver 36 frames por segundo retiro apenas 12 aleatoriamente\n",
    "#        -> Este processo é repetido 3 vezes para os 3 segundos\n",
    "#        -> Passo estes 3 gestos de 36 frames à rede e fico com a moda dos resultados\n",
    "\n",
    "class Sub_Distributed_frames():\n",
    "    import random\n",
    "    \n",
    "    def __init__(self,frames,thread_id):\n",
    "        self.random1 = self.random(2,frames,thread_id)\n",
    "        #self.random2 = self.random(10,frames,thread_id)\n",
    "        #self.random3 = self.random(7,frames,thread_id)\n",
    "        #self.l = len(frames)\n",
    "        \n",
    "    def getrandom(self):\n",
    "        return self.random1\n",
    "    \n",
    "    #retorna 12 frames random entre as que o pc consegue tirar num segundo\n",
    "    def random(self,seed,frames,thread_id):\n",
    "        random.seed(seed)\n",
    "        final_idx = []\n",
    "        \n",
    "        if(len(frames)) < 12:\n",
    "            #print('Len de frames after: {}'.format(len(frames)))\n",
    "            #print('Shape: {}'.format(frames[0].shape))\n",
    "            return list(cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (100,75))/255 for frame in frames)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            total_divisions = len(frames) // 12\n",
    "        \n",
    "            #vou de retirar 12 frames de todos os blocos de frames que o total_divisions me devolve\n",
    "            for i in range(0,12):\n",
    "            \n",
    "                #lista currente de indices\n",
    "                list_idx = [tmp for tmp in range(total_divisions*i,total_divisions*(i+1))]\n",
    "                #escolho 1 indice aleatório\n",
    "                idx = random.choices(list_idx, k=1)[0]\n",
    "                #acrescento-o à lista\n",
    "                final_idx.append(idx)\n",
    "        \n",
    "            return list(np.asarray(Image.fromarray(cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB)).resize((100,75)))/255. for i in final_idx )\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedFrames():\n",
    "    #frames ficam distribuidas em 3 listas, correspondetes a cada segundo\n",
    "    #cada lista é utilizada por uma thread para processamento\n",
    "    #utilizo listas, pois como demonstrado em cima são mais rápidas\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.handling_future = threading.Event()\n",
    "        self.stopped = False\n",
    "        \n",
    "        self.list1 = [] #lista1\n",
    "        self.list2 = [] #lista2\n",
    "        self.list3 = [] #lista3\n",
    "        \n",
    "        self.current_list = 1\n",
    "        \n",
    "        self.e1 = threading.Event() #evento para a thread1\n",
    "        self.e2 = threading.Event() #evento para a thread2\n",
    "        self.e3 = threading.Event() #evento para a thread3\n",
    "        \n",
    "        self.t1 = Thread(target=self.thread_function, args=(1,self.e1), daemon=True) #thread1\n",
    "        self.t2 = Thread(target=self.thread_function, args=(2,self.e2), daemon=True) #thread2 \n",
    "        self.t3 = Thread(target=self.thread_function, args=(3,self.e3), daemon=True) #thread3\n",
    "        \n",
    "        self.t1.start()\n",
    "        self.t2.start()\n",
    "        self.t3.start()\n",
    "        \n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        \n",
    "    def list_prox(self):\n",
    "        \n",
    "        cl = self.current_list\n",
    "        \n",
    "        global heartbeat_event\n",
    "        global buffer\n",
    "        #caso esteja na lista1, thread1 processa e siga\n",
    "        if(cl == 1):\n",
    "            \n",
    "            self.e1.set()\n",
    "            while(len(self.list1)!=12):\n",
    "                #time.sleep(0.001)\n",
    "                pass\n",
    "            self.current_list +=1\n",
    "            \n",
    "            heartbeat_event.set()\n",
    "            \n",
    "        #caso esteja na lista2, thread2 processa e siga\n",
    "        elif(cl == 2):\n",
    "        \n",
    "            self.e2.set()\n",
    "            while(len(self.list2)!=12):\n",
    "                #time.sleep(0.001)\n",
    "                pass\n",
    "            self.current_list +=1\n",
    "        \n",
    "            heartbeat_event.set()\n",
    "            \n",
    "                #caso esteja na lista3, thread3 processa, dá pull da thread mais antiga e volta à thread 1\n",
    "        elif(cl == 3):\n",
    "            #heartbeat_lock.acquire()\n",
    "            self.e3.set()\n",
    "            \n",
    "            while(len(self.list3)!=12):\n",
    "                #time.sleep(0.001)\n",
    "                pass\n",
    "        \n",
    "            self.current_list +=1\n",
    "            \n",
    "            heartbeat_event.set()\n",
    "            \n",
    "            \n",
    "        elif(cl == 4):\n",
    "            \n",
    "            self.list1 = self.list2\n",
    "            self.list2 = self.list3\n",
    "            self.list3 = buffer\n",
    "            buffer = []\n",
    "            self.e3.set()\n",
    "            \n",
    "            heartbeat_event.set()\n",
    "            \n",
    "            \n",
    "    def append(self,frame):\n",
    "        global buffer\n",
    "        l = self.current_list\n",
    "        \n",
    "        if(l == 1):\n",
    "            self.list1.append(frame)\n",
    "        elif(l == 2):\n",
    "            self.list2.append(frame)\n",
    "        elif(l == 3):\n",
    "            self.list3.append(frame)\n",
    "        elif(l == 4):\n",
    "            buffer.append(frame)\n",
    "        \n",
    "    \n",
    "    def set_event(self,id_thread):\n",
    "        if(id_thread == 1):\n",
    "            self.e1.set()\n",
    "        elif(id_thread == 2):\n",
    "            self.e2.set()\n",
    "        elif(id_thread == 3):\n",
    "            self.e3.set()\n",
    "               \n",
    "    #thread function\n",
    "    #**\n",
    "    #id_thread - representa o id_thread\n",
    "    #e - representa o evento da thread\n",
    "    #**\n",
    "    def thread_function(self,id_thread,e):\n",
    "        \n",
    "        global processing_permission\n",
    "        global processing_counter\n",
    "        global frames\n",
    "        global lock\n",
    "        #enquanto não estiver pronto para executar espera    \n",
    "        '''while not e.isSet():\n",
    "            e.wait()'''\n",
    "        if(id_thread == 1):\n",
    "            \n",
    "            while not self.e1.isSet():\n",
    "                self.e1.wait()\n",
    "            \n",
    "            #thread 1 com as 12 frames\n",
    "            self.list1 = Sub_Distributed_frames(self.list1,id_thread).random1\n",
    "            self.e1.clear()\n",
    "             \n",
    "        elif(id_thread == 2):\n",
    "                \n",
    "            while not self.e2.isSet():\n",
    "                self.e2.wait()\n",
    "            \n",
    "            #thread 2 com as 12 frames\n",
    "            self.list2 = Sub_Distributed_frames(self.list2,id_thread).random1\n",
    "            self.e2.clear()\n",
    "            \n",
    "            \n",
    "        elif(id_thread == 3):\n",
    "            \n",
    "            #enquanto stop != True, processa\n",
    "            while not self.stopped:\n",
    "                while not self.e3.isSet():\n",
    "                    self.e3.wait()\n",
    "                \n",
    "               \n",
    "                #vai buscar as 12 frames\n",
    "                self.list3 = Sub_Distributed_frames(self.list3,id_thread).random1\n",
    "                \n",
    "                \n",
    "                \n",
    "                if (processing_permission == True):\n",
    "                    \n",
    "                    processing_counter +=1\n",
    "                    \n",
    "                   \n",
    "                if processing_counter == 2:\n",
    "                    list_3 = self.list3.copy()\n",
    "                    tam1 = len(self.list1)\n",
    "                    tam2 = len(self.list2)\n",
    "                    tam3 = len(self.list3)\n",
    "                    \n",
    "                    frames[0,(tam1+tam2):(tam1+tam2+tam3)] = np.asarray(list_3)\n",
    "                    frames[0,tam1:(tam1+tam2)] = np.asarray(self.list2)\n",
    "                    frames[0,0:tam1] = np.asarray(self.list1)\n",
    "                    \n",
    "                    main_model_event.set()\n",
    "                    processing_counter = 0\n",
    "                    processing_permission = False\n",
    "                \n",
    "                self.e3.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeMarker():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stopped = False\n",
    "        \n",
    "    def start(self):\n",
    "        Thread(target=self.set_marker, args=(),daemon=True).start()\n",
    "        \n",
    "    def set_marker(self):\n",
    "        global lock\n",
    "        global distributed_frames\n",
    "        global heartbeat_event\n",
    "        \n",
    "        while not self.stopped:\n",
    "            \n",
    "            endtime = timer() + 1\n",
    "            while timer() <= endtime:\n",
    "                pass\n",
    "            \n",
    "            #depois de passar 1 segundo, vai buscar todas as frames de esse segundo, dá lock na class, retira só as 12 frames do segundo\n",
    "            #e muda de lista, passa para a lista 2 correspondente ao 2 segundo.\n",
    "            lock.acquire()\n",
    "            \n",
    "            distributed_frames.list_prox()   \n",
    "            \n",
    "            while not heartbeat_event.isSet():\n",
    "                heartbeat_event.wait()\n",
    "            heartbeat_event.clear()\n",
    "            \n",
    "            lock.release()\n",
    "        \n",
    "        print(\"Time Marker stopped, cya\")\n",
    "        \n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGet():\n",
    "    \"\"\"\n",
    "    Class that continuously gets frames from a VideoCapture object\n",
    "    with a dedicated thread.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, src=0):\n",
    "    \n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "        \n",
    "    def start(self):    \n",
    "        Thread(target=self.get, args=(),daemon=True).start()\n",
    "        return self\n",
    "\n",
    "    def get(self):\n",
    "        \n",
    "        global lock\n",
    "        global distributed_frames\n",
    "        global frame\n",
    "        global lock_main_thread\n",
    "        global hand_thread_event\n",
    "        \n",
    "        start = datetime.now()\n",
    "        \n",
    "        #Se der stopped esta função termina e acaba a thread(função está em baixo, stop)\n",
    "        while not self.stopped:\n",
    "            #grabbed é no caso de erros inesperados, daí o self.stream.read em cima no init\n",
    "            if not self.grabbed:\n",
    "                self.stop()\n",
    "            else:\n",
    "                #apanha frames enquanto não tiver em stop\n",
    "                (_ , self.frame) = self.stream.read()\n",
    "        \n",
    "                #lock \n",
    "                lock.acquire()\n",
    "                \n",
    "                self.frame = cv2.flip(self.frame,1)\n",
    "               \n",
    "                distributed_frames.append(self.frame)\n",
    "                \n",
    "                lock.release()\n",
    "                \n",
    "                frame = self.frame\n",
    "                hand_thread_event.set()\n",
    "                    \n",
    "                \n",
    "        print(\"Video Get stopped, cya :)\")\n",
    "        self.stream.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "            \n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def save_frames(frames):\n",
    "    \n",
    "    step = 0\n",
    "    for frame in frames:\n",
    "        \n",
    "        if step < 10:\n",
    "            name = str(step) + \".jpg\"\n",
    "            matplotlib.image.imsave(\"/Users/guilhermeviveiros/Desktop/LEI/Fotos/\"+name, frame)\n",
    "        else:\n",
    "            name = str(step) + \".jpg\"\n",
    "            matplotlib.image.imsave(\"/Users/guilhermeviveiros/Desktop/LEI/Fotos/\"+name, frame)\n",
    "            \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "When we pass this function to pycharm or .py use this code to terminate this function.\n",
    "Doens't work in notebook, so for now i will stop after 30 iterations\n",
    "try:\n",
    "    while True:\n",
    "        print(\"cousas\")\n",
    "        time.sleep(5)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "'''\n",
    "\n",
    "'''\n",
    "When we pass this function to pycharm or .py use this code to terminate this function.\n",
    "Doens't work in notebook, so for now i will stop after 30 iterations\n",
    "try:\n",
    "    while True:\n",
    "        print(\"cousas\")\n",
    "        time.sleep(5)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "'''\n",
    "\n",
    "def threadVideoGet(source=0):\n",
    "    \"\"\"\n",
    "    Dedicated thread for grabbing video frames with VideoGet object.\n",
    "    Main thread shows video frames.\n",
    "    \"\"\"\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.disable_v2_behavior()\n",
    "    \n",
    "    video_getter = VideoGet(source).start()\n",
    "    print('Comecou o video getter')\n",
    "    cps = CountsPerSec().start()\n",
    "    time.sleep(1)\n",
    "    start = datetime.now()\n",
    "    global distributed_frames\n",
    "    global frame\n",
    "    global frames\n",
    "    global processing_permission\n",
    "    time_marker = TimeMarker().start()   \n",
    "        \n",
    "    i = 0\n",
    "    \n",
    "    with detection_graph.as_default():\n",
    "    \n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "                model = load_model('/Users/guilhermeviveiros/Desktop/simple_model/best_model_13_sgd_nesterov_800k_custom_dataset.h5')\n",
    "                #model._make_predict_function() \n",
    "                \n",
    "                print(\"Ready to start\")\n",
    "                \n",
    "                while True:         \n",
    "                \n",
    "                    #fica à espera que a thread responsável pela captura de imagens, devolva uma frame\n",
    "                    while not hand_thread_event.isSet():\n",
    "                        hand_thread_event.wait()\n",
    "                    \n",
    "                    #print(\"Frame received\")\n",
    "                    \n",
    "                    #Transformação da frame para ser compatível com o modelo de and detection                \n",
    "                    image_np = imutils.resize(frame, width=600)\n",
    "                    image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                \n",
    "                    #Tudo do tensorflow\n",
    "                    image_np_expanded = np.expand_dims(image_np,axis=0)\n",
    "                    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "                    \n",
    "                    (boxes, scores, classes, num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "                        \n",
    "                    # Visualization of the results of a detection.\n",
    "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                        image_np,\n",
    "                        np.squeeze(boxes),\n",
    "                        np.squeeze(classes).astype(np.int32),\n",
    "                        np.squeeze(scores),\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=True,\n",
    "                        max_boxes_to_draw = 1,\n",
    "                        min_score_thresh=0.90,\n",
    "                        line_thickness=8)\n",
    "                    \n",
    "                    #Display of frame\n",
    "                    cv2.imshow(\"Frame\", image_np)\n",
    "                    \n",
    "                    #Pronto para outra frame\n",
    "                    hand_thread_event.clear()\n",
    "                    \n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                     \n",
    "                    condition = scores[0][0]*100     \n",
    "                    \n",
    "                    if(condition >= 90):\n",
    "                                            \n",
    "                        print(condition)\n",
    "                        \n",
    "                        #Sinal para enviar os 3 segundos de frames entre a deteção da mão\n",
    "                        processing_permission = True\n",
    "                        \n",
    "                        #Enquanto não estiverem processados o tempo que falta, espera\n",
    "                        while not main_model_event.isSet():\n",
    "                            main_model_event.wait()\n",
    "                        \n",
    "                        \n",
    "                        print('Starting prediction')\n",
    "                        \n",
    "                        save_frames(frames[0])\n",
    "                        l = model.predict(frames)\n",
    "                        print(l)\n",
    "                        l = np.argmax(l)\n",
    "                        \n",
    "                        if(l == 0):\n",
    "                            print(\"Doing other things\")\n",
    "                        elif(l==1):\n",
    "                            print(\"Swipping down\")\n",
    "                            minimize()\n",
    "                        elif(l==2):\n",
    "                            print(\"Swipping left\")\n",
    "                            swipe('right')\n",
    "                        elif(l==3):\n",
    "                            print(\"Zooming\") \n",
    "                            scale('+')\n",
    "                        \n",
    "                        #pronto para o próximo gesto\n",
    "                        main_model_event.clear()\n",
    "                        \n",
    "                        #frames volta tudo a 0, sem frames\n",
    "                        frames = np.zeros(shape=(1,36,75,100,3))\n",
    "                        \n",
    "                        #tempo para esvaziar buffers\n",
    "                        time.sleep(2)\n",
    "                        \n",
    "                        print('Ready to detect again')\n",
    "                        \n",
    "                print(\"Leaving\")\n",
    "                #time_marker.stop()    \n",
    "                video_getter.stop()\n",
    "                cv2.destroyAllWindows()\n",
    "                print(\"Done\")\n",
    "                #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Comecou o video getter\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Ready to start\n",
      "94.83778476715088\n",
      "Starting prediction\n",
      "[[6.1275507e-08 2.1071755e-06 9.2567509e-11 9.9999785e-01]]\n",
      "Zooming\n",
      "Ready to detect again\n",
      "92.11339950561523\n",
      "Starting prediction\n",
      "[[1.36686190e-10 1.06453314e-01 1.02510195e-10 8.93546641e-01]]\n",
      "Zooming\n",
      "Ready to detect again\n",
      "96.45787477493286\n",
      "Starting prediction\n",
      "[[3.3145914e-10 9.9999809e-01 4.0258733e-08 1.8798321e-06]]\n",
      "Swipping down\n",
      "Ready to detect again\n",
      "97.04683423042297\n",
      "Starting prediction\n",
      "[[2.0754017e-04 8.1149215e-01 3.3907734e-05 1.8826637e-01]]\n",
      "Swipping down\n",
      "Ready to detect again\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ea0a7f19180c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#Função principal que trata de tudo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mthreadVideoGet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Leaving\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b0bed60f33d9>\u001b[0m in \u001b[0;36mthreadVideoGet\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     73\u001b[0m                     (boxes, scores, classes, num_detections) = sess.run(\n\u001b[1;32m     74\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_detections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                     feed_dict={image_tensor: image_np_expanded})\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0;31m# Visualization of the results of a detection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#É o que organiza as 36 frames\n",
    "distributed_frames = DistributedFrames()\n",
    "\n",
    "# locks para trabalhar com as variaveis globais\n",
    "lock = Lock()\n",
    "lock_main_thread = Lock()\n",
    "\n",
    "#variaveis global\n",
    "frame = None\n",
    "frames = np.zeros(shape=(1,36,75,100,3))\n",
    "processing_counter = 0\n",
    "debug_counter = 0\n",
    "buffer = []\n",
    "\n",
    "\n",
    "#Eventos para processamento de imagem e gesto\n",
    "hand_thread_event = threading.Event() #informar sinal que encontrou a mão\n",
    "main_model_event = threading.Event()\n",
    "heartbeat_event = threading.Event() #Verficação das threads\n",
    "\n",
    "\n",
    "processing_permission = False #mandar as 36 frames correspondentes aos 3 segundos\n",
    "\n",
    "#Função principal que trata de tudo\n",
    "threadVideoGet()\n",
    "\n",
    "print(\"Leaving\")\n",
    "distributed_frames.stop()\n",
    "\n",
    "print(\"All done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
