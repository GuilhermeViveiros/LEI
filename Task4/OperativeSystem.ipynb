{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't forget to change the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread,Lock\n",
    "import cv2\n",
    "from cv2 import imwrite\n",
    "import time\n",
    "from time import monotonic as timer\n",
    "import os\n",
    "import cv2\n",
    "from ExecuteGesture import scale,swipe,minimize\n",
    "from pynput.keyboard import Key\n",
    "import numpy as np\n",
    "import queue\n",
    "import threading\n",
    "import random\n",
    "import imutils\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "#import tensorflow.compat.v1 as tf\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                             2.0.0      \n",
      "tensorflow-estimator                   2.0.1      \n",
      "tensorflow-object-detection-api        0.1.1      \n"
     ]
    }
   ],
   "source": [
    "!pip list | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo de deteção de mão\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load do modelo do tensorflow, que faz a deteção da mão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/guilhermeviveiros/Desktop/models/research/object_detection\"\n",
    "MODEL_NAME = 'hand_graph'\n",
    "PATH_TO_CKPT = path + '/' + MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = os.path.join(path+'/training', 'labelmap.pbtxt')\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.compat.v1.get_default_graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "label_map_util.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contador de tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class CountsPerSec:\n",
    "    \"\"\"\n",
    "    Class that tracks the number of occurrences (\"counts\") of an\n",
    "    arbitrary event and returns the frequency in occurrences\n",
    "    (counts) per second. The caller must increment the count.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "        self._num_occurrences = 0\n",
    "\n",
    "    def start(self):\n",
    "        self._start_time = datetime.now()\n",
    "        return self\n",
    "\n",
    "    def increment(self):\n",
    "        self._num_occurrences += 1\n",
    "\n",
    "    def countsPerSec(self):\n",
    "        \n",
    "        elapsed_time = (datetime.now() - self._start_time).total_seconds()\n",
    "        return self._num_occurrences / elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "\n",
    "\n",
    "def putIterationsPerSec(frame, iterations_per_sec):\n",
    "    \"\"\"\n",
    "    Add iterations per second text to lower-left corner of a frame.\n",
    "    \"\"\"\n",
    "\n",
    "    cv2.putText(frame, \"{:.0f} iterations/sec\".format(iterations_per_sec),\n",
    "        (10, 450), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vou escolher random entre as frames que tenho num segundo até ter 12 frames\n",
    "#Exemplo -> Se obtiver 36 frames por segundo retiro apenas 12 aleatoriamente\n",
    "#        -> Este processo é repetido 3 vezes para os 3 segundos\n",
    "#        -> Passo estes 3 gestos de 36 frames à rede e fico com a moda dos resultados\n",
    "\n",
    "class Sub_Distributed_frames():\n",
    "    import random\n",
    "    \n",
    "    def __init__(self,frames):\n",
    "        self.random1 = self.random(2,frames)\n",
    "        self.random2 = self.random(10,frames)\n",
    "        self.random3 = self.random(7,frames)\n",
    "        self.l = len(frames)\n",
    "        \n",
    "    def getrandom(self):\n",
    "        return self.random1\n",
    "    \n",
    "    def random(self,seed,frames):\n",
    "        random.seed(seed)\n",
    "        final_idx = []\n",
    "        \n",
    "        \n",
    "        if(len(frames)) < 12:\n",
    "            return list(cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (75,100))/255 for frame in frames)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            total_divisions = len(frames) // 12\n",
    "        \n",
    "            #vou de retirar 12 frames de todos os blocos de frames que o total_divisions me devolve\n",
    "            for i in range(0,12):\n",
    "            \n",
    "                #lista currente de indices\n",
    "                list_idx = [tmp for tmp in range(total_divisions*i,total_divisions*(i+1))]\n",
    "                #escolho 1 indice aleatório\n",
    "                idx = random.choices(list_idx, k=1)[0]\n",
    "                #acrescento-o à lista\n",
    "                final_idx.append(idx)\n",
    "        \n",
    "    \n",
    "            return list(cv2.resize(cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB), (75,100))/255 for i in final_idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedFrames():\n",
    "    #frames ficam distribuidas em 3 listas, correspondetes a cada segundo\n",
    "    #cada lista é utilizada por uma thread para processamento\n",
    "    #utilizo listas, pois como demonstrado em cima são mais rápidas\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        from tensorflow.keras.models import load_model\n",
    "        self.model = load_model('/Users/guilhermeviveiros/Desktop/best_model_10_sgd_nesterov_800k.h5')\n",
    "        \n",
    "        self.list1 = [] #lista1\n",
    "        self.list2 = [] #lista2\n",
    "        self.list3 = [] #lista3\n",
    "        \n",
    "        self.current_list = 1\n",
    "        \n",
    "        self.e1 = threading.Event() #evento para a thread1\n",
    "        self.e2 = threading.Event() #evento para a thread2\n",
    "        self.e3 = threading.Event() #evento para a thread3\n",
    "        \n",
    "        self.t1 = threading.Thread(target=self.thread_function, args=(1,self.e1), daemon=True) #thread1\n",
    "        self.t2 = threading.Thread(target=self.thread_function, args=(2,self.e2), daemon=True) #thread2 \n",
    "        self.t3 = threading.Thread(target=self.thread_function, args=(3,self.e3), daemon=True) #thread3\n",
    "        \n",
    "        self.t1.start()\n",
    "        self.t2.start()\n",
    "        self.t3.start()\n",
    "        \n",
    "        self.stopped = False\n",
    "        self.make_copies = False\n",
    "        \n",
    "        self.copies = {}\n",
    "        self.await_futture_list = True\n",
    "        \n",
    "    \n",
    "    def list_prox(self):\n",
    "        \n",
    "        cl = self.current_list\n",
    "        \n",
    "        #caso esteja na lista1, thread1 processa e siga\n",
    "        if(cl == 1):\n",
    "            self.set_event(1)\n",
    "            while(len(self.list1)>12):\n",
    "                time.sleep(0.001)\n",
    "                \n",
    "            self.current_list +=1\n",
    "            \n",
    "        #caso esteja na lista2, thread2 processa e siga\n",
    "        elif(cl == 2):\n",
    "        \n",
    "            self.set_event(2)\n",
    "            while(len(self.list2)>12):\n",
    "                time.sleep(0.001)\n",
    "            \n",
    "            self.current_list +=1\n",
    "        \n",
    "        #caso esteja na lista3, thread3 processa, dá pull da thread mais antiga e volta à thread 1\n",
    "        elif(cl == 3):\n",
    "            self.set_event(3)\n",
    "            \n",
    "            \n",
    "            while(len(self.list3)>12):\n",
    "                time.sleep(0.001)\n",
    "                \n",
    "            #print(\"Chegamos ao fim de 3 segundos\")\n",
    "            #print(\"Lista 1 com \" + str(len(self.list1)))\n",
    "            #print(\"Lista 2 com \" + str(len(self.list2)))\n",
    "            #print(\"Lista 3 com \" + str(len(self.list3)))\n",
    "            \n",
    "            #Caso tenha previsto a mão, faz cópias para a memória das frames\n",
    "            if(self.make_copies == True):\n",
    "                #na primeira iteração guarda o passado e o presente\n",
    "                if(self.await_future_list == True):\n",
    "                    self.copies[\"list1\"] = self.list2\n",
    "                    self.copies[\"list2\"] = self.list3\n",
    "                    self.await_future_list = False\n",
    "                #na segunda iteração guarda o \"futuro\"\n",
    "                else:\n",
    "                    self.copies[\"list3\"] = self.list3\n",
    "                    self.make_copies = False\n",
    "            \n",
    "            else:\n",
    "                self.list1 = self.list2\n",
    "                self.list2 = self.list3\n",
    "                self.list3 = []\n",
    "                \n",
    "            \n",
    "            \n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "    \n",
    "    def append(self,frame):\n",
    "        \n",
    "        l = self.current_list\n",
    "        \n",
    "        if(l == 1):\n",
    "            self.list1.append(frame)\n",
    "        elif(l == 2):\n",
    "            self.list2.append(frame)\n",
    "        elif(l == 3):\n",
    "            self.list3.append(frame)\n",
    "    \n",
    "    def set_event(self,id_thread):\n",
    "        if(id_thread == 1):\n",
    "            self.e1.set()\n",
    "        elif(id_thread == 2):\n",
    "            self.e2.set()\n",
    "        elif(id_thread == 3):\n",
    "            self.e3.set()\n",
    "               \n",
    "    #thread function\n",
    "    #**\n",
    "    #id_thread - representa o id_thread\n",
    "    #e - representa o evento da thread\n",
    "    #**\n",
    "    def thread_function(self,id_thread,e):\n",
    "        #enquanto não estiver pronto para executar espera    \n",
    "        while not e.isSet():\n",
    "            e.wait()\n",
    "            if(id_thread == 1):\n",
    "                self.list1 = Sub_Distributed_frames(self.list1).random1\n",
    "            \n",
    "            elif(id_thread == 2):\n",
    "                self.list2 = Sub_Distributed_frames(self.list2).random1\n",
    "                \n",
    "            elif(id_thread == 3):\n",
    "                self.list3 = Sub_Distributed_frames(self.list3).random1        \n",
    "                \n",
    "                #volta a bloquear a flag apenas se for a última thread, enquanto a thread main não der e.set fica bloequado\n",
    "                if(self.stopped == False):\n",
    "                    e.clear()\n",
    "            \n",
    "            #apenas bloqueio na última porque as outras qd acabam de fazer a operação uma vez, morrem\n",
    "        \n",
    "            \n",
    "            print(\"The list \" + str(id_thread) + \" is concluded\")\n",
    "            \n",
    "    def predict_model():\n",
    "        self.make_copies = True\n",
    "        \n",
    "        while(self.make_copies == True):\n",
    "            time.sleep(0.3)\n",
    "        \n",
    "        for i in self.copies:\n",
    "            print(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#df = DistributedFrames()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeMarker():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stopped = False\n",
    "        \n",
    "    def start(self):\n",
    "        Thread(target=self.set_marker, args=()).start()\n",
    "        \n",
    "    def set_marker(self):\n",
    "        global lock\n",
    "        global distributed_frames\n",
    "        while not self.stopped:\n",
    "            \n",
    "            endtime = timer() + 1\n",
    "            while timer() <= endtime:\n",
    "                pass\n",
    "            \n",
    "            lock.acquire()\n",
    "            distributed_frames.list_prox()\n",
    "            lock.release()\n",
    "        \n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "class is_hand():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.e = threading.Event() #evento para a thread1\n",
    "        self.t1 = threading.Thread(target=self.process_frame, args=(self.e,)) #thread1\n",
    "        self.is_hand = False\n",
    "        self.frame = None\n",
    "        self.processed = False\n",
    "        \n",
    "        self.t1.start()\n",
    "    \n",
    "    def check_hand(self,frame):\n",
    "                \n",
    "        self.frame = frame\n",
    "        self.e.set()\n",
    "        \n",
    "        while(self.processed == False):\n",
    "            time.sleep(0.01)\n",
    "        \n",
    "        self.processed = False\n",
    "        return self.is_hand\n",
    "        \n",
    "    \n",
    "    def process_frame(self,e):\n",
    "        \n",
    "        while not e.isSet():\n",
    "            \n",
    "            e.wait()\n",
    "            \n",
    "            with detection_graph.as_default():\n",
    "                \n",
    "                with tf.Session(graph=detection_graph) as sess:\n",
    "                                        \n",
    "                    #frame = imutils.resize(self.frame, width=600)\n",
    "                    frame = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "\n",
    "                    image_np = frame\n",
    "                    image_np_expanded = np.expand_dims(image_np,axis=0)\n",
    "                    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "                              \n",
    "                    (boxes, scores, classes, num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "                                        \n",
    "                    condition = scores[0][0]*100                    \n",
    "                    \n",
    "                    if(condition >= 90): \n",
    "                        self.is_hand = True\n",
    "                    \n",
    "                    self.processed = True\n",
    "                        \n",
    "            e.clear()\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGet():\n",
    "    \"\"\"\n",
    "    Class that continuously gets frames from a VideoCapture object\n",
    "    with a dedicated thread.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, src=0):\n",
    "    \n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "        self.hand_detected = False\n",
    "        \n",
    "    def start(self):    \n",
    "        Thread(target=self.get, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def get(self):\n",
    "        global lock\n",
    "        global distributed_frames\n",
    "        global frame\n",
    "        \n",
    "        ih = is_hand()\n",
    "        \n",
    "        start = datetime.now()\n",
    "        \n",
    "        \n",
    "        while not self.stopped:\n",
    "            if not self.grabbed:\n",
    "                self.stop()\n",
    "            else:\n",
    "              \n",
    "                (_ , self.frame) = self.stream.read()\n",
    "                lock.acquire()\n",
    "                distributed_frames.append(self.frame)\n",
    "                lock.release()\n",
    "                \n",
    "                if(self.hand_detected == False):\n",
    "                    print(\"Checking\")\n",
    "                    check_hand = ih.check_hand(self.frame)\n",
    "                    \n",
    "                    if(check_hand == True):\n",
    "                        \n",
    "                        print(\"Hand found\")\n",
    "                        self.hand_detected = True\n",
    "                        distributed_frames.predict_model()\n",
    "                    \n",
    "                \n",
    "                \n",
    "                           \n",
    "            \n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threadVideoGet(source=0):\n",
    "    \"\"\"\n",
    "    Dedicated thread for grabbing video frames with VideoGet object.\n",
    "    Main thread shows video frames.\n",
    "    \"\"\"\n",
    "    \n",
    "    #tf.disable_v2_behavior()\n",
    "    video_getter = VideoGet(source).start()\n",
    "    cps = CountsPerSec().start()\n",
    "    time.sleep(1)\n",
    "    start = datetime.now()\n",
    "    time_marker = TimeMarker().start()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "distributed_frames = DistributedFrames()\n",
    "time.sleep(1)\n",
    "lock = Lock()\n",
    "#threadVideoGet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = cv2.imread(\"/Users/guilhermeviveiros/Desktop/Part_01/1083/00001.jpg\")\n",
    "\n",
    "#plt.imshow(frame)\n",
    "\n",
    "ih = is_hand()\n",
    "ih.check_hand(frame)\n",
    "#print(is_hand(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames(frames):\n",
    "    \n",
    "    for (step,frame) in enumerate(frames):\n",
    "        \n",
    "        if step < 10:\n",
    "            imwrite(\"/Users/guilhermeviveiros/Desktop/LEI/Fotos/0\" + str(step) + \".jpg\", frame)\n",
    "        else:\n",
    "            imwrite(\"/Users/guilhermeviveiros/Desktop/LEI/Fotos/\" + str(step) + \".jpg\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sampling THREADED frames from webcam...\n",
      "Ready to start\n",
      "90.90155363082886\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "91.95363521575928\n",
      "[[1. 0. 0. 0.]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "94.10557150840759\n",
      "[[0. 0. 1. 0.]]\n",
      "Swipping left\n",
      "Ready to capute the hand\n",
      "97.75825142860413\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "97.84116744995117\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "92.66498684883118\n",
      "[[0.000000e+00 0.000000e+00 1.000000e+00 7.571057e-10]]\n",
      "Swipping left\n",
      "Ready to capute the hand\n",
      "99.99263882637024\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "96.3716983795166\n",
      "[[0. 1. 0. 0.]]\n",
      "Swipping down\n",
      "Ready to capute the hand\n",
      "92.23003387451172\n",
      "[[3.0764449e-10 7.1985878e-06 9.9999285e-01 3.3361897e-10]]\n",
      "Swipping left\n",
      "Ready to capute the hand\n",
      "99.48129653930664\n",
      "[[0.7787322  0.         0.         0.22126786]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "99.78511333465576\n",
      "[[0.0000e+00 0.0000e+00 1.0000e+00 5.9851e-36]]\n",
      "Swipping left\n",
      "Ready to capute the hand\n",
      "97.78552055358887\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "98.5431432723999\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00 2.1427723e-37]]\n",
      "Swipping left\n",
      "Ready to capute the hand\n",
      "93.36760640144348\n",
      "[[3.6680678e-01 8.6526895e-36 6.3319319e-01 2.0759130e-17]]\n",
      "Swipping left\n",
      "Ready to capute the hand\n",
      "99.91803169250488\n",
      "[[0.000000e+00 1.000000e+00 0.000000e+00 4.104124e-20]]\n",
      "Swipping down\n",
      "Ready to capute the hand\n",
      "98.79204034805298\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 8.2334316e-17]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "97.5263237953186\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "99.52691197395325\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "94.73603963851929\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "97.01375961303711\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 6.3144093e-23]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "98.43558073043823\n",
      "[[1. 0. 0. 0.]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "99.33505058288574\n",
      "[[1.830587e-16 7.556305e-12 0.000000e+00 1.000000e+00]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "96.37477397918701\n",
      "[[1. 0. 0. 0.]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "99.77471828460693\n",
      "[[0. 0. 1. 0.]]\n",
      "Swipping left\n",
      "Ready to capute the hand\n",
      "99.68466758728027\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "91.95355176925659\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "98.7269401550293\n",
      "[[9.9998176e-01 0.0000000e+00 0.0000000e+00 1.8180721e-05]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "99.97200965881348\n",
      "[[0.0000000e+00 2.0378027e-15 0.0000000e+00 1.0000000e+00]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "97.32261896133423\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "92.93144941329956\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "97.35084772109985\n",
      "[[7.6535314e-16 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "99.92711544036865\n",
      "[[1. 0. 0. 0.]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "95.03406286239624\n",
      "[[1.0000000e+00 0.0000000e+00 8.8241454e-12 1.4446514e-12]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "98.74714612960815\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "99.23949241638184\n",
      "[[0. 0. 1. 0.]]\n",
      "Swipping left\n",
      "Ready to capute the hand\n",
      "97.28471040725708\n",
      "[[0. 0. 0. 1.]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "98.74626398086548\n",
      "[[3.477595e-24 0.000000e+00 6.051534e-38 1.000000e+00]]\n",
      "Zooming\n",
      "Ready to capute the hand\n",
      "99.60629940032959\n",
      "[[1. 0. 0. 0.]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "99.73808526992798\n",
      "[[1.0000000e+00 0.0000000e+00 3.0925635e-25 0.0000000e+00]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n",
      "90.09532332420349\n",
      "[[0. 0. 1. 0.]]\n",
      "Swipping left\n",
      "Ready to capute the hand\n",
      "92.772376537323\n",
      "[[1. 0. 0. 0.]]\n",
      "Doing other things\n",
      "Ready to capute the hand\n"
     ]
    }
   ],
   "source": [
    "## import threading\n",
    "print(\"[INFO] sampling THREADED frames from webcam...\")\n",
    "vs = cv2.VideoCapture(0)\n",
    "detect_hand = True\n",
    "\n",
    "\n",
    "i = 0\n",
    "frames = np.zeros(shape=(36,75,100,3))\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    \n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "            \n",
    "            model = load_model('/Users/guilhermeviveiros/Desktop/simple_model/best_model_6_supersimple.h5')\n",
    "            model._make_predict_function() \n",
    "            print(\"Ready to start\")\n",
    "            while True:\n",
    "                \n",
    "                ret,frame = vs.read()\n",
    "                frame = cv2.flip(frame,1)\n",
    "                frame = imutils.resize(frame, width=600)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # check to see if the frame should be displayed to our screen\n",
    "                if detect_hand == True:\n",
    "                    \n",
    "                    image_np = frame\n",
    "                    image_np_expanded = np.expand_dims(image_np,axis=0)\n",
    "                    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "                      \n",
    "                    \n",
    "                        \n",
    "                        \n",
    "                    (boxes, scores, classes, num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "                    \n",
    "                    # Visualization of the results of a detection.\n",
    "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                        image_np,\n",
    "                        np.squeeze(boxes),\n",
    "                        np.squeeze(classes).astype(np.int32),\n",
    "                        np.squeeze(scores),\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=True,\n",
    "                        max_boxes_to_draw = 2,\n",
    "                        min_score_thresh=0.90,\n",
    "                        line_thickness=8)\n",
    "                    \n",
    "                    cv2.imshow(\"Frame\", frame)\n",
    "                    \n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                    \n",
    "                    condition = scores[0][0]*100                    \n",
    "                        \n",
    "                    if(condition >= 90):\n",
    "                        print(condition)\n",
    "                        detect_hand = False\n",
    "                    \n",
    "                    \n",
    "                            \n",
    "                            \n",
    "                #começa a processar o gesto\n",
    "                if(detect_hand == False):\n",
    "                    \n",
    "                    cv2.imshow(\"Frame\", frame)\n",
    "                    \n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                    \n",
    "                    frame = cv2.resize(frame, (100,75))\n",
    "                    frames[i] =  frame\n",
    "                    i +=1;\n",
    "                    \n",
    "                    if(i == 36):\n",
    "                        \n",
    "                        #save_frames(frames)\n",
    "                        l = model.predict([[frames]])\n",
    "                        print(l)\n",
    "                        l = np.argmax(l)\n",
    "                        \n",
    "                        if(l == 0):\n",
    "                            print(\"Doing other things\")\n",
    "                        elif(l==1):\n",
    "                            print(\"Swipping down\")\n",
    "                            minimize()\n",
    "                        elif(l==2):\n",
    "                            print(\"Swipping left\")\n",
    "                            swipe('right')\n",
    "                        elif(l==3):\n",
    "                            print(\"Zooming\") \n",
    "                            scale('+')\n",
    "                        detect_hand = True\n",
    "                        i=0\n",
    "                        \n",
    "                        time.sleep(1)\n",
    "                        frames = np.zeros(shape=(36,75,100,3))\n",
    "                        print(\"Ready to capute the hand\")\n",
    "                        \n",
    "            # do a bit of cleanup\n",
    "            #vs.stream.release()\n",
    "            vs.release()\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
